{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the base path before executing code\n",
    "Base_path = \"/home/tennistetris/Documents/Data Analytics/Hall/Inter_hall\"\n",
    "data1 = \"NAV_data\"\n",
    "data2 = \"Mix\"\n",
    "Path_to_data = os.path.join(Base_path,data1,data2)\n",
    "files = os.listdir(Path_to_data)\n",
    "os.chdir(Path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Continuous_dates(Values):\n",
    "    '''\n",
    "    This function takes an intermittent pandas series indexed by date \n",
    "    and converts it to a continuous pandas series where missing values\n",
    "    are replaced by the Naive Method (prev. value)    \n",
    "    '''\n",
    "    Index  = Values.index\n",
    "    Start_date = Index[0]\n",
    "    End_date = Index[len(Index)-1]\n",
    "    Num_dates = (End_date - Start_date).days\n",
    "    Cont_dates = pd.date_range(Start_date ,End_date)\n",
    "    ts = pd.Series(np.zeros(len(Cont_dates)),index = Cont_dates)\n",
    "    i = 0;j = 0\n",
    "    while(j<len(Index)):\n",
    "        #print (i,' : ',Cont_dates[i]);print(j,' : ',Index[j])\n",
    "        if((Cont_dates[i] - Index[j]).days == 0):\n",
    "            ts[i] = Values.iloc[j] \n",
    "            i = i+1;j=j+1\n",
    "        elif((Cont_dates[i] - Index[j]).days < 0):\n",
    "            ts[i] = Values.iloc[j-1]\n",
    "            i = i+1\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(Path_to_data)\n",
    "db = pd.read_csv('100033.csv')\n",
    "Index = list()\n",
    "for i in range(db.shape[0]):\n",
    "    Index.append(dt.datetime.strptime(db.iloc[i,6],'%d-%b-%Y'))\n",
    "NAV = pd.Series(db[db.columns[3]])\n",
    "NAV.index = Index\n",
    "NAV = Continuous_dates(NAV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quarterly_Returns = pd.Series(np.zeros(len(NAV)),index =NAV.index)\n",
    "Time_lag = 91 #Since we are calculating Quaterly Returns\n",
    "              #Each quarter is assumed to have 91 days\n",
    "for i in range(len(NAV)):\n",
    "    t2 = i\n",
    "    t1 = max(0,(i-Time_lag))\n",
    "    Quarterly_Returns[i]  = np.log(NAV[t2]/NAV[t1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "List1 = ['01' , '04' , '07' , '10']\n",
    "List2 = ['2013' , '2014' , '2015' , '2016' , '2017']\n",
    "Quarters = list(itertools.product(List1,List2))\n",
    "\n",
    "List3 = list()\n",
    "\n",
    "for i in range(len(Quarters)):\n",
    "    temp = Quarters[i]\n",
    "    temp = temp[1]+'-'+temp[0]\n",
    "    temp = pd.Period(temp,'Q')\n",
    "    List3.append(temp)\n",
    "    \n",
    "Quarters = pd.Series(List3).sort_values().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "Start_date = Quarterly_Returns.index[0].to_pydatetime()\n",
    "End_date = Quarterly_Returns.index[len(NAV)-1].to_pydatetime()\n",
    "#Now to sort the Quarters Series so as to only contain valid quarters\n",
    "Valid_quarters = []\n",
    "Valid_quarters_indices = []\n",
    "for i in range(len(Quarters)):\n",
    "    if (Quarters[i].end_time.to_pydatetime())>=Start_date:\n",
    "        if (Quarters[i].start_time.to_pydatetime())<=End_date:\n",
    "            Valid_quarters.append(Quarters[i])\n",
    "Index = pd.Series(Valid_quarters)\n",
    "print type(Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013Q1   -0.049426\n",
      "2013Q2   -0.038899\n",
      "2013Q3   -0.025241\n",
      "2013Q4    0.108927\n",
      "2014Q1    0.059256\n",
      "2014Q2    0.184241\n",
      "2014Q3    0.129207\n",
      "2014Q4    0.093428\n",
      "2015Q1    0.115777\n",
      "2015Q2   -0.006196\n",
      "2015Q3    0.026964\n",
      "2015Q4   -0.034050\n",
      "2016Q1   -0.057974\n",
      "2016Q2    0.080383\n",
      "2016Q3    0.138917\n",
      "2016Q4   -0.012411\n",
      "2017Q1    0.042709\n",
      "2017Q2    0.095495\n",
      "2017Q3    0.079664\n",
      "2017Q4    0.046593\n",
      "Freq: Q-DEC, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "Avg_quarterly_returns = pd.Series(np.zeros(len(Index)),Index) \n",
    "k = 0  # this variable is there to track the dates in NAV data\n",
    "Quarterly_dates = Quarterly_Returns.index\n",
    "Avg_Quarterly_Returns = list()\n",
    "#print len(Quarterly_dates)\n",
    "for i in range(len(Index)):\n",
    "    #print ('i : ',i)\n",
    "    Sum_quarterly = 0\n",
    "    num = 0\n",
    "    while((Quarterly_dates[k] < Index[i].start_time) or (Quarterly_dates[k]<Quarterly_dates[0])):\n",
    "        k = k+1\n",
    "        #print ('Quarterly_dates : ',Quarterly_dates[k])\n",
    "        #print ('start_date',Index[i].start_time)\n",
    "        #print ('k1 :',k)\n",
    "    while (k < 1824) and ((Quarterly_dates[k]<=Quarterly_Returns.index[len(Quarterly_Returns)-1]) and (Quarterly_dates[k]<=Index[i].end_time)):\n",
    "        Sum_quarterly = Sum_quarterly + Quarterly_Returns[k]\n",
    "        k = k+1\n",
    "        #print ('k2:',k)\n",
    "        num = num+1\n",
    "        #print ('num :',num)\n",
    "    Mean = Sum_quarterly/num\n",
    "    Avg_quarterly_returns[i] = Mean\n",
    "print Avg_quarterly_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#Doing zero padding of data to make downstream processing easier\n",
    "Avg_quartery_returns_padded = pd.Series(np.zeros(len(Quarters)),Quarters)\n",
    "Avg_quarterly_returns_index = Avg_quarterly_returns.index\n",
    "for i in range(len(Avg_quartery_returns_padded)):\n",
    "    if Quarters[i] in Avg_quarterly_returns_index:\n",
    "        Avg_quartery_returns_padded[i] = Avg_quarterly_returns[i]\n",
    "    else:\n",
    "        Avg_quarterly_returns_padded[i] = 0\n",
    "print len(Avg_quarterly_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tennistetris/Documents/Data Analytics/Hall/Inter_hall/NAV_quarterly\n"
     ]
    }
   ],
   "source": [
    "Base_path = \"/home/tennistetris/Documents/Data Analytics/Hall/Inter_hall\"\n",
    "if not 'NAV_quarterly' in os.listdir(Base_path):\n",
    "    os.mkdir('NAV_quarterly')\n",
    "Write_path = os.path.join(Base_path,'NAV_quarterly') \n",
    "print Write_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tennistetris/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Avg_quarterly_Returns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-731ca2317dd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m#    else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m#        Avg_quarterly_returns_padded[i] = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAvg_quarterly_Returns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWrite_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mAvg_quarterly_returns_padded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AUM_quarterly_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Avg_quarterly_Returns' is not defined"
     ]
    }
   ],
   "source": [
    "List1 = ['01' , '04' , '07' , '10']\n",
    "List2 = ['2013' , '2014' , '2015' , '2016' , '2017']\n",
    "Quarters = list(itertools.product(List1,List2))\n",
    "\n",
    "List3 = list()\n",
    "\n",
    "for i in range(len(Quarters)):\n",
    "    temp = Quarters[i]\n",
    "    temp = temp[1]+'-'+temp[0]\n",
    "    temp = pd.Period(temp,'Q')\n",
    "    List3.append(temp)\n",
    "    \n",
    "Quarters = pd.Series(List3).sort_values().reset_index(drop = True)\n",
    "\n",
    "os.chdir(Path_to_data)\n",
    "files = os.listdir(Path_to_data)\n",
    "for file in files:\n",
    "    #Reading Data\n",
    "    os.chdir(Path_to_data)\n",
    "    db = pd.read_csv(file)\n",
    "    #Indexing the dates\n",
    "    Index = list()\n",
    "    for i in range(db.shape[0]):\n",
    "        Index.append(dt.datetime.strptime(db.iloc[i,6],'%d-%b-%Y'))\n",
    "    NAV = pd.Series(db[db.columns[3]])\n",
    "    NAV.index = Index\n",
    "    NAV = Continuous_dates(NAV)  # To convert to continupus timeseries data\n",
    "    #Finding the Quarterly Returns\n",
    "    Quarterly_Returns = pd.Series(np.zeros(len(NAV)),index =NAV.index)\n",
    "    Time_lag = 91 #Since we are calculating Quaterly Returns\n",
    "              #Each quarter is assumed to have 91 days\n",
    "    for i in range(len(NAV)):\n",
    "        t2 = i\n",
    "        t1 = max(0,(i-Time_lag))\n",
    "        Quarterly_Returns[i]  = np.log(NAV[t2]/NAV[t1])\n",
    "    #Now to sort the Quarters Series so as to only contain valid quarters\n",
    "    Start_date = Quarterly_Returns.index[0].to_pydatetime()\n",
    "    End_date = Quarterly_Returns.index[len(Quarterly_Returns)-1].to_pydatetime()\n",
    "    Valid_quarters = []\n",
    "    Valid_quarters_indices = []\n",
    "    for i in range(len(Quarters)):\n",
    "        if (Quarters[i].end_time.to_pydatetime())>=Start_date:\n",
    "            if (Quarters[i].start_time.to_pydatetime())<=End_date:\n",
    "                Valid_quarters.append(Quarters[i])\n",
    "    Index = pd.Series(Valid_quarters)\n",
    "    \n",
    "    #Finding the average quarterly reports\n",
    "    Avg_quarterly_returns = pd.Series(np.zeros(len(Index)),Index) \n",
    "    k = 0  # this variable is there to track the dates in NAV data\n",
    "    Quarterly_dates = Quarterly_Returns.index\n",
    "    Avg_quarterly_returns = list()\n",
    "    #print len(Quarterly_dates)\n",
    "    for i in range(len(Index)):\n",
    "        #print ('i : ',i)\n",
    "        Sum_quarterly = 0\n",
    "        num = 0\n",
    "        while((Quarterly_dates[k] < Index[i].start_time) or (Quarterly_dates[k]<Quarterly_dates[0])):\n",
    "            k = k+1\n",
    "            #print ('Quarterly_dates : ',Quarterly_dates[k])\n",
    "            #print ('start_date',Index[i].start_time)\n",
    "            #print ('k1 :',k)\n",
    "        while (k < len(NAV)) and ((Quarterly_dates[k]<=Quarterly_Returns.index[len(Quarterly_Returns)-1]) and (Quarterly_dates[k]<=Index[i].end_time)):\n",
    "            Sum_quarterly = Sum_quarterly + Quarterly_Returns[k]\n",
    "            k = k+1\n",
    "            #print ('k2:',k)\n",
    "            num = num+1\n",
    "            #print ('num :',num)\n",
    "        Mean = Sum_quarterly/num\n",
    "        Avg_quarterly_returns[i] = Mean\n",
    "        \n",
    "    Doing zero padding of data to make downstream processing easier\n",
    "    Avg_quarterly_returns_padded = pd.Series(np.zeros(len(Quarters)),Quarters)\n",
    "    Avg_quarterly_returns_index = Avg_quarterly_returns.index\n",
    "    for i in range(len(Avg_quartery_returns_padded)):\n",
    "        if Quarters[i] in Avg_quarterly_returns_index:\n",
    "            Avg_quarterly_returns_padded[i] = Avg_quarterly_returns[i]\n",
    "        else:\n",
    "            Avg_quarterly_returns_padded[i] = 0\n",
    "    print len(Avg_quarterly_returns_padded)\n",
    "    os.chdir(Write_path)\n",
    "    Avg_quarterly_returns_padded.to_csv('AUM_quarterly_'+file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
